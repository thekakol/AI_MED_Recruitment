{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU0_NP0T3fmO"
      },
      "source": [
        "# Overview of the asignment\n",
        "TF I'm trying to achieve here?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QP8sMqCNavH"
      },
      "source": [
        "# Required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YTaL2FLTNXmJ"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import pandas\n",
        "import plotly.express as px\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedStratifiedKFold, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,confusion_matrix\n",
        "#Classifiers\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtSbe02BNgS3"
      },
      "source": [
        "# Creating the Data table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "ACZ8LAM_Ivm2",
        "outputId": "ee167fc5-e311-4939-9942-29a2be054309"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'task_data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3118178536.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Three columns are saved as string datatype, however they contain float data that can be useful for the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#This motivates us to change these columns form string into float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtask_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'task_data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'CTR - Cardiothoracic Ratio'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Inscribed circle radius'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Heart perimeter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'task_data.csv'"
          ]
        }
      ],
      "source": [
        "#Three columns are saved as string datatype, however they contain float data that can be useful for the model\n",
        "#This motivates us to change these columns form string into float\n",
        "task_data = pandas.read_csv('task_data.csv', delimiter=',')\n",
        "print(task_data.dtypes, \"\\n\")\n",
        "for string in ('CTR - Cardiothoracic Ratio','Inscribed circle radius','Heart perimeter'):\n",
        "  task_data[string] = task_data[string].str.replace(',','.')\n",
        "  task_data[string] = task_data[string].astype(float)\n",
        "print(task_data.dtypes, \"\\n\")\n",
        "task_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j38T039rY7Ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wrYF1y3TWTe"
      },
      "source": [
        "# Preparing data (to make something useful out of this)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quD8_1dGTWDN"
      },
      "outputs": [],
      "source": [
        "usefulData = task_data[[\"Heart width\", \"Lung width\", \"xx\",\"yy\",\"xy\",\"normalized_diff\",\"Inscribed circle radius\", \"Polygon Area Ratio\", \"Heart perimeter\", \"Heart area \",\"Lung area\" ]]\n",
        "usefulData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADuYRQ2mVFPc"
      },
      "outputs": [],
      "source": [
        "result = task_data['Cardiomegaly']\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FPzui15W94Y"
      },
      "source": [
        "# Dividing data into train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBSAcUqAVZv7"
      },
      "outputs": [],
      "source": [
        "trainData, testData, trainResult, testResult = train_test_split(usefulData, result, test_size=0.2, random_state=69)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLgB0Apt70S6"
      },
      "source": [
        "# Weird shit starts here\n",
        "No one will stop me from optimising everything"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9StdYDFy0PKr"
      },
      "source": [
        "# WE CAN GO BIGGER\n",
        "We'll apply all possible methods, because no one will stop me"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3eEBdtZ5nU_"
      },
      "source": [
        "# **Universal Optimatisation Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeRGNQAw5tEv"
      },
      "outputs": [],
      "source": [
        "def pipeOptimiser(classificator, parameters):\n",
        "  rskf = RepeatedStratifiedKFold(\n",
        "    n_splits=5,\n",
        "    n_repeats=20,\n",
        "    random_state=None\n",
        "  )\n",
        "\n",
        "  pipe = Pipeline(steps=[\n",
        "      (\"scaler\", StandardScaler()),\n",
        "      (\"model\", classificator())\n",
        "  ])\n",
        "  test = classificator()\n",
        "  grid_search = GridSearchCV(\n",
        "    estimator=pipe,\n",
        "\n",
        "    param_grid=parameters,\n",
        "    scoring=\"accuracy\",\n",
        "    cv=rskf,\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        "  )\n",
        "  grid_search.fit(trainData, trainResult)\n",
        "  return ( grid_search.best_params,grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2RyQV2oQr12"
      },
      "source": [
        "#K - nearest neighbors\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mr6QQV5L7NZT"
      },
      "outputs": [],
      "source": [
        "#Finding best parameters for K - nearest neighbors\n",
        "param_grid = {\n",
        "    \"model__n_neighbors\": [1,2,3,4],\n",
        "    \"model__weights\": [\"uniform\", \"distance\"],\n",
        "    \"model__metric\": [\"minkowski\", \"manhattan\", \"euclidean\", \"chebyshev\"],\n",
        "}\n",
        "best_params_pipe_knn, best_score = pipeOptimiser(KNeighborsClassifier, param_grid)\n",
        "print(f\"Best parameters: {best_params_pipe_knn}\")\n",
        "print(f\"Best accuracy (averaged CV): {best_score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBOSAhfAo_YM"
      },
      "outputs": [],
      "source": [
        "#Testing the train data set with found parameters\n",
        "pipe_knn = Pipeline(steps=[\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"model\", KNeighborsClassifier(\n",
        "        n_neighbors = best_params_pipe_knn['model__n_neighbors'],\n",
        "        weights     = best_params_pipe_knn['model__weights'],\n",
        "        metric      = best_params_pipe_knn['model__metric'],\n",
        "    ))\n",
        "])\n",
        "pipe_knn.fit(trainData, trainResult)\n",
        "cv_score = numpy.round(cross_val_score(pipe_knn, trainData, trainResult), 2)\n",
        "print(\"Scores of training data cross-validation (each fold):\")\n",
        "list(map(print, cv_score))\n",
        "print(f\"\\nCross-validation mean score: {numpy.mean(cv_score):.3}\")\n",
        "print(f\"Standard deviation of CV score: {numpy.std(cv_score):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNqI20iD0rwd"
      },
      "source": [
        "# Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcK16dbgfJRN"
      },
      "outputs": [],
      "source": [
        "#Finding best parameters for Support Vector Machine\n",
        "param_grid = {\n",
        "    \"model__kernel\":[\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
        "    \"model__C\":[1,2,3,4],\n",
        "    \"model__gamma\":[\"scale\",\"auto\"],\n",
        "    \"model__class_weight\":[\"balanced\",None]\n",
        "}\n",
        "best_params_pipe_svc, best_score = pipeOptimiser(SVC, param_grid)\n",
        "print(f\"Best parameters: {best_params_pipe_svc}\")\n",
        "print(f\"Best accuracy (averaged CV): {best_score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52p5Vcwb1Tfz"
      },
      "outputs": [],
      "source": [
        "pipe_svc = Pipeline(steps=[\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"model\", SVC(                  # Support Vector Classifier\n",
        "        kernel=best_params_pipe_svc[\"model__kernel\"],               # RBF kernel captures non-linear decision boundaries\n",
        "        C=best_params_pipe_svc[\"model__C\"],                        # Regularization strength (higher = tighter fit to training data)\n",
        "        gamma=best_params_pipe_svc[\"model__gamma\"],              # Kernel width; 'scale' adapts to data variance\n",
        "        class_weight=best_params_pipe_svc[\"model__class_weight\"]           # Treat classes equally (no re-weighting)\n",
        "    ))\n",
        "])\n",
        "\n",
        "pipe_svc.fit(trainData, trainResult)\n",
        "\n",
        "cv_score = numpy.round(cross_val_score(pipe_svc, trainData, trainResult), 2)\n",
        "\n",
        "print(\"Scores of training data cross-validation (each fold):\")\n",
        "list(map(print, cv_score))\n",
        "print(f\"\\nCross-validation mean score: {cv_score.mean():.3f}\")\n",
        "print(f\"Standard deviation of CV score: {cv_score.std():.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeWOgc2c15zc"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EaIGkoUfKAl"
      },
      "outputs": [],
      "source": [
        "#Finding best parameters for Logistic Regression\n",
        "param_grid = {\n",
        "  \"model__C\":[1,2,3],\n",
        "  \"model__penalty\":[\"l1\", \"l2\", \"elasticnet\", None],\n",
        "  \"model__solver\":[\"lbfgs\", \"liblinear\", \"newton-cg\", \"newton-cholesky\", \"sag\", \"saga\"],\n",
        "  \"model__max_iter\":[1000,10000],\n",
        "  \"model__class_weight\":[\"balanced\",None],\n",
        "}\n",
        "best_params_pipe_log, best_score = pipeOptimiser(LogisticRegression, param_grid)\n",
        "print(f\"Best parameters: {best_params_pipe_log}\")\n",
        "print(f\"Best accuracy (averaged CV): {best_score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CReJfC6217DU"
      },
      "outputs": [],
      "source": [
        "pipe_log = Pipeline(steps=[\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"model\", LogisticRegression(\n",
        "        C=best_params_pipe_log[\"model__C\"],\n",
        "        penalty=best_params_pipe_log[\"model__penalty\"],\n",
        "        solver=best_params_pipe_log[\"model__solver\"],\n",
        "        max_iter=best_params_pipe_log[\"model__max_iter\"],\n",
        "        class_weight=best_params_pipe_log[\"model__class_weight\"]\n",
        "    ))\n",
        "])\n",
        "\n",
        "pipe_log.fit(trainData, trainResult)\n",
        "\n",
        "cv_score = numpy.round(cross_val_score(pipe_log, trainData, trainResult), 2)\n",
        "\n",
        "print(\"Scores of training data cross-validation (each fold):\")\n",
        "list(map(print, cv_score))\n",
        "print(f\"\\nCross-validation mean score: {cv_score.mean():.3f}\")\n",
        "print(f\"Standard deviation of CV score: {cv_score.std():.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtx0-U6y2R4w"
      },
      "source": [
        "# Running the Model on the Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4cAtAlv2UpE"
      },
      "outputs": [],
      "source": [
        "#Predicting for all models\n",
        "y_pred_knn  = pipe_knn.predict(testData)\n",
        "y_pred_svc  = pipe_svc.predict(testData)\n",
        "y_pred_log  = pipe_log.predict(testData)\n",
        "\n",
        "#Evaluating all models\n",
        "#Accuracy\n",
        "acc_knn  = accuracy_score(testResult, y_pred_knn)\n",
        "acc_svc  = accuracy_score(testResult, y_pred_svc)\n",
        "acc_log  = accuracy_score(testResult, y_pred_log)\n",
        "#Precision\n",
        "prec_knn  = precision_score(testResult, y_pred_knn)\n",
        "prec_svc  = precision_score(testResult, y_pred_svc)\n",
        "prec_log  = precision_score(testResult, y_pred_log)\n",
        "#Recall\n",
        "recall_knn  = recall_score(testResult, y_pred_knn)\n",
        "recall_svc  = recall_score(testResult, y_pred_svc)\n",
        "recall_log  = recall_score(testResult, y_pred_log)\n",
        "#F1\n",
        "f1_knn  = f1_score(testResult, y_pred_knn)\n",
        "f1_svc  = f1_score(testResult, y_pred_svc)\n",
        "f1_log  = f1_score(testResult, y_pred_log)\n",
        "print(f\"Accuracy on test set:\")\n",
        "print(f\"- Accuracy of KNN Classifier model on test dataset:                     {acc_knn:.4f}\")\n",
        "print(f\"- Accuracy of SVC model on test dataset:                                {acc_svc:.4f}\")\n",
        "print(f\"- Accuracy of Logistic Regression model on test dataset:                {acc_log:.4f}\")\n",
        "print(f\"\\n Precision on test set:\")\n",
        "print(f\"- Precision of KNN Classifier model on test dataset:                    {prec_knn:.4f}\")\n",
        "print(f\"- Precision of SVC model on test dataset:                               {prec_svc:.4f}\")\n",
        "print(f\"- Precision of Logistic Regression model on test dataset:               {prec_log:.4f}\")\n",
        "print(f\"\\n Recall on test set:\")\n",
        "print(f\"- Recall of KNN Classifier model on test dataset:                       {recall_knn:.4f}\")\n",
        "print(f\"- Recall of SVC model on test dataset:                                  {recall_svc:.4f}\")\n",
        "print(f\"- Recall of Logistic Regression model on test dataset:                  {recall_log:.4f}\")\n",
        "print(f\"\\n F1 on test set:\")\n",
        "print(f\"- F1 of KNN Classifier model on test dataset:                           {f1_knn:.4f}\")\n",
        "print(f\"- F1 of SVC model on test dataset:                                      {f1_svc:.4f}\")\n",
        "print(f\"- F1 of Logistic Regression model on test dataset:                      {f1_log:.4f}\")\n",
        "print(f\"Confusion matrix on test data\")\n",
        "print(f\"- Confusion matrix of KNN Classifier model on test dataset:             {confusion_matrix(testResult,y_pred_knn)}\")\n",
        "print(f\"- Confusion matrix of SVC model on test dataset:                        {confusion_matrix(testResult,y_pred_svc)}\")\n",
        "print(f\"- Confusion matrix of Logistic Regression model on test dataset:        {confusion_matrix(testResult,y_pred_log)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "J2RyQV2oQr12",
        "yNqI20iD0rwd",
        "ZeWOgc2c15zc"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}